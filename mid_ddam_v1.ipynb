{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Facial Expression Classification\n",
        "\n",
        "# You will provided a training dataset, so you can design your model and propose a solution you think is the best for this case.\n",
        "\n",
        "# Overall there are 8 different facial expressions in a dataset. Of course in real-world it would be a much bigger number, but even this number is not that easy to correctly identify. So your dataset contains the following classes of facial expressions:\n",
        "\n",
        "\n",
        "# '0' : 'Anger'\n",
        "# '1' : 'Contempt'\n",
        "# '2' : 'Disgust'\n",
        "# '3' : 'Fear'\n",
        "# '4' : 'Happy'\n",
        "# '5' : 'Neutral'\n",
        "# '6' : 'Sad'\n",
        "# '7' : 'Surprise'\n",
        "\n",
        "# This example is a short guideline with a model to show you how to get a correct submission file.\n",
        "\n",
        "# BUT REMEMBER: Provided model shows a result arruracy below 50% which is NOT sufficient for a final result."
      ],
      "metadata": {
        "id": "Xi6hFHfn3bej"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from IPython.display import clear_output\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                               transforms.PILToTensor(),\n",
        "                               v2.ToDtype(torch.float32, scale=True),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "metadata": {
        "id": "sDL6HvvHdLTQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1jjGULBTHgxfpgriRWW0vRm99qMNUGlzD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kynkjjwOciBs",
        "outputId": "846b9a1b-ea75-4274-9e36-1ff7fc512c8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1jjGULBTHgxfpgriRWW0vRm99qMNUGlzD\n",
            "From (redirected): https://drive.google.com/uc?id=1jjGULBTHgxfpgriRWW0vRm99qMNUGlzD&confirm=t&uuid=53d2e889-f498-44db-aeda-9db9c6b87f82\n",
            "To: /content/test_dataset.zip\n",
            "100% 52.6M/52.6M [00:01<00:00, 46.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1MBczmIad-re3SOf_ml6d7BTCNDkCUAFR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DkbXBzYWJzj",
        "outputId": "c754171d-852d-41f2-98d5-1543d949bebc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1MBczmIad-re3SOf_ml6d7BTCNDkCUAFR\n",
            "From (redirected): https://drive.google.com/uc?id=1MBczmIad-re3SOf_ml6d7BTCNDkCUAFR&confirm=t&uuid=f32a3389-9df0-40cb-acba-38610d639790\n",
            "To: /content/train_dataset.zip\n",
            "100% 212M/212M [00:04<00:00, 51.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip test_dataset.zip\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "TKWbKkG_dAVK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip train_dataset.zip\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "eVRLGTh4-wjX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrm-X7cygbEw",
        "outputId": "0f4f5f42-e160-4b1b-c0e5-02cfc6a844a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O face_landmarker_v2_with_blendshapes.task -q https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task"
      ],
      "metadata": {
        "id": "lg8y3Rrogd3_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mediapipe import solutions\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def draw_landmarks_on_image(rgb_image, detection_result):\n",
        "  face_landmarks_list = detection_result.face_landmarks\n",
        "  annotated_image = np.copy(rgb_image)\n",
        "\n",
        "  # Loop through the detected faces to visualize.\n",
        "  for idx in range(len(face_landmarks_list)):\n",
        "    face_landmarks = face_landmarks_list[idx]\n",
        "\n",
        "    # Draw the face landmarks.\n",
        "    face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
        "    face_landmarks_proto.landmark.extend([\n",
        "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n",
        "    ])\n",
        "\n",
        "    solutions.drawing_utils.draw_landmarks(\n",
        "        image=annotated_image,\n",
        "        landmark_list=face_landmarks_proto,\n",
        "        connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n",
        "        landmark_drawing_spec=None,\n",
        "        connection_drawing_spec=mp.solutions.drawing_styles\n",
        "        .get_default_face_mesh_tesselation_style())\n",
        "    solutions.drawing_utils.draw_landmarks(\n",
        "        image=annotated_image,\n",
        "        landmark_list=face_landmarks_proto,\n",
        "        connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n",
        "        landmark_drawing_spec=None,\n",
        "        connection_drawing_spec=mp.solutions.drawing_styles\n",
        "        .get_default_face_mesh_contours_style())\n",
        "    solutions.drawing_utils.draw_landmarks(\n",
        "        image=annotated_image,\n",
        "        landmark_list=face_landmarks_proto,\n",
        "        connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n",
        "          landmark_drawing_spec=None,\n",
        "          connection_drawing_spec=mp.solutions.drawing_styles\n",
        "          .get_default_face_mesh_iris_connections_style())\n",
        "\n",
        "  return annotated_image\n",
        "\n",
        "def plot_face_blendshapes_bar_graph(face_blendshapes):\n",
        "  # Extract the face blendshapes category names and scores.\n",
        "  face_blendshapes_names = [face_blendshapes_category.category_name for face_blendshapes_category in face_blendshapes]\n",
        "  face_blendshapes_scores = [face_blendshapes_category.score for face_blendshapes_category in face_blendshapes]\n",
        "  # The blendshapes are ordered in decreasing score value.\n",
        "  face_blendshapes_ranks = range(len(face_blendshapes_names))\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(12, 12))\n",
        "  bar = ax.barh(face_blendshapes_ranks, face_blendshapes_scores, label=[str(x) for x in face_blendshapes_ranks])\n",
        "  ax.set_yticks(face_blendshapes_ranks, face_blendshapes_names)\n",
        "  ax.invert_yaxis()\n",
        "\n",
        "  # Label each bar with values\n",
        "  for score, patch in zip(face_blendshapes_scores, bar.patches):\n",
        "    plt.text(patch.get_x() + patch.get_width(), patch.get_y(), f\"{score:.4f}\", va=\"top\")\n",
        "\n",
        "  ax.set_xlabel('Score')\n",
        "  ax.set_title(\"Face Blendshapes\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "kMQmwcD8gfv4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "import cv2\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# STEP 2: Create an FaceLandmarker object.\n",
        "base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')\n",
        "\n",
        "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
        "                                       output_face_blendshapes=True,\n",
        "                                       output_facial_transformation_matrixes=True,\n",
        "                                       num_faces=2)\n",
        "\n",
        "detector = vision.FaceLandmarker.create_from_options(options)\n",
        "\n",
        "# STEP 3: Load the input image.\n",
        "image = mp.Image.create_from_file(\"/content/test/images/10370.png\")\n",
        "\n",
        "# STEP 4: Detect face landmarks from the input image.\n",
        "detection_result = detector.detect(image)\n",
        "\n",
        "# STEP 5: Process the detection result. In this case, visualize it.\n",
        "annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
        "cv2_imshow(cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "5vpqj4F8gh__",
        "outputId": "45b106f7-2b59-4cf1-85a1-37dac37362f3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=96x96>"
            ],
            "image/png": "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\n",
            "image/jpeg": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image.numpy_view()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "96ysq_JGdZ-K",
        "outputId": "e7a25845-d78c-4949-d9bb-4e3a059959d7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[  0,   0,   2],\n",
              "        [  0,   0,   2],\n",
              "        [  0,   0,   2],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   2],\n",
              "        [  0,   0,   2],\n",
              "        [  0,   0,   2],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 99,  99,  99],\n",
              "        [  2,   2,   2],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [122,  97,  90],\n",
              "        [124,  99,  94],\n",
              "        [124, 101,  95]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  2,   2,   2],\n",
              "        ...,\n",
              "        [127, 100,  93],\n",
              "        [128, 103,  96],\n",
              "        [128, 103,  96]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  2,   2,   2],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [130, 103,  94],\n",
              "        [129, 104,  97],\n",
              "        [128, 103,  96]]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-5372a4aa-d22c-40f3-81cf-7e9beda87703\" class=\"ndarray_repr\"><pre>ndarray (96, 96, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,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\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[  0,   0,   2],\n",
              "        [  0,   0,   2],\n",
              "        [  0,   0,   2],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   2],\n",
              "        [  0,   0,   2],\n",
              "        [  0,   0,   2],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 99,  99,  99],\n",
              "        [  2,   2,   2],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [122,  97,  90],\n",
              "        [124,  99,  94],\n",
              "        [124, 101,  95]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  2,   2,   2],\n",
              "        ...,\n",
              "        [127, 100,  93],\n",
              "        [128, 103,  96],\n",
              "        [128, 103,  96]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  2,   2,   2],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [130, 103,  94],\n",
              "        [129, 104,  97],\n",
              "        [128, 103,  96]]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-5372a4aa-d22c-40f3-81cf-7e9beda87703 button').onclick = (e) => {\n",
              "        document.querySelector('#id-5372a4aa-d22c-40f3-81cf-7e9beda87703').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-5372a4aa-d22c-40f3-81cf-7e9beda87703 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detection_result.face_blendshapes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc6bGCd2b9tD",
        "outputId": "f1e621c0-b6b0-4b1c-93a8-bff15658c93c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Category(index=0, score=5.162095476407558e-06, display_name='', category_name='_neutral'),\n",
              "  Category(index=1, score=0.22077958285808563, display_name='', category_name='browDownLeft'),\n",
              "  Category(index=2, score=0.15250913798809052, display_name='', category_name='browDownRight'),\n",
              "  Category(index=3, score=0.00624827528372407, display_name='', category_name='browInnerUp'),\n",
              "  Category(index=4, score=0.007714663632214069, display_name='', category_name='browOuterUpLeft'),\n",
              "  Category(index=5, score=0.03385905548930168, display_name='', category_name='browOuterUpRight'),\n",
              "  Category(index=6, score=2.315387064300012e-05, display_name='', category_name='cheekPuff'),\n",
              "  Category(index=7, score=5.579902335739462e-07, display_name='', category_name='cheekSquintLeft'),\n",
              "  Category(index=8, score=1.6904937183426227e-06, display_name='', category_name='cheekSquintRight'),\n",
              "  Category(index=9, score=0.06423023343086243, display_name='', category_name='eyeBlinkLeft'),\n",
              "  Category(index=10, score=0.06346447765827179, display_name='', category_name='eyeBlinkRight'),\n",
              "  Category(index=11, score=0.2130013108253479, display_name='', category_name='eyeLookDownLeft'),\n",
              "  Category(index=12, score=0.25210344791412354, display_name='', category_name='eyeLookDownRight'),\n",
              "  Category(index=13, score=0.0009787882445380092, display_name='', category_name='eyeLookInLeft'),\n",
              "  Category(index=14, score=0.7259523272514343, display_name='', category_name='eyeLookInRight'),\n",
              "  Category(index=15, score=0.6987514495849609, display_name='', category_name='eyeLookOutLeft'),\n",
              "  Category(index=16, score=0.006011337507516146, display_name='', category_name='eyeLookOutRight'),\n",
              "  Category(index=17, score=0.048292145133018494, display_name='', category_name='eyeLookUpLeft'),\n",
              "  Category(index=18, score=0.037889741361141205, display_name='', category_name='eyeLookUpRight'),\n",
              "  Category(index=19, score=0.45194366574287415, display_name='', category_name='eyeSquintLeft'),\n",
              "  Category(index=20, score=0.2865297496318817, display_name='', category_name='eyeSquintRight'),\n",
              "  Category(index=21, score=0.013193189166486263, display_name='', category_name='eyeWideLeft'),\n",
              "  Category(index=22, score=0.011504748836159706, display_name='', category_name='eyeWideRight'),\n",
              "  Category(index=23, score=8.062816777965054e-05, display_name='', category_name='jawForward'),\n",
              "  Category(index=24, score=0.00020425688126124442, display_name='', category_name='jawLeft'),\n",
              "  Category(index=25, score=0.003906708676367998, display_name='', category_name='jawOpen'),\n",
              "  Category(index=26, score=0.00031071537523530424, display_name='', category_name='jawRight'),\n",
              "  Category(index=27, score=0.0007166430004872382, display_name='', category_name='mouthClose'),\n",
              "  Category(index=28, score=0.00827470887452364, display_name='', category_name='mouthDimpleLeft'),\n",
              "  Category(index=29, score=0.0020388003904372454, display_name='', category_name='mouthDimpleRight'),\n",
              "  Category(index=30, score=0.013216875493526459, display_name='', category_name='mouthFrownLeft'),\n",
              "  Category(index=31, score=0.016781650483608246, display_name='', category_name='mouthFrownRight'),\n",
              "  Category(index=32, score=0.00011142036237288266, display_name='', category_name='mouthFunnel'),\n",
              "  Category(index=33, score=0.0006057014688849449, display_name='', category_name='mouthLeft'),\n",
              "  Category(index=34, score=0.00010117334750248119, display_name='', category_name='mouthLowerDownLeft'),\n",
              "  Category(index=35, score=0.0002962074941024184, display_name='', category_name='mouthLowerDownRight'),\n",
              "  Category(index=36, score=0.24276047945022583, display_name='', category_name='mouthPressLeft'),\n",
              "  Category(index=37, score=0.02562795765697956, display_name='', category_name='mouthPressRight'),\n",
              "  Category(index=38, score=0.001791957183741033, display_name='', category_name='mouthPucker'),\n",
              "  Category(index=39, score=0.0005971802747808397, display_name='', category_name='mouthRight'),\n",
              "  Category(index=40, score=0.06472237408161163, display_name='', category_name='mouthRollLower'),\n",
              "  Category(index=41, score=0.0035856140311807394, display_name='', category_name='mouthRollUpper'),\n",
              "  Category(index=42, score=0.14700117707252502, display_name='', category_name='mouthShrugLower'),\n",
              "  Category(index=43, score=0.019540393725037575, display_name='', category_name='mouthShrugUpper'),\n",
              "  Category(index=44, score=0.0034317313693463802, display_name='', category_name='mouthSmileLeft'),\n",
              "  Category(index=45, score=0.0016588278813287616, display_name='', category_name='mouthSmileRight'),\n",
              "  Category(index=46, score=0.005491560325026512, display_name='', category_name='mouthStretchLeft'),\n",
              "  Category(index=47, score=0.024674441665410995, display_name='', category_name='mouthStretchRight'),\n",
              "  Category(index=48, score=6.961139297345653e-05, display_name='', category_name='mouthUpperUpLeft'),\n",
              "  Category(index=49, score=4.700762656284496e-05, display_name='', category_name='mouthUpperUpRight'),\n",
              "  Category(index=50, score=1.1078324178015464e-06, display_name='', category_name='noseSneerLeft'),\n",
              "  Category(index=51, score=2.6118614186998457e-06, display_name='', category_name='noseSneerRight')]]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbBMqhUfgugJ",
        "outputId": "336d158f-8215-47ab-ca24-fd27918a3d4c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.162095476407558e-06,\n",
              " 0.22077958285808563,\n",
              " 0.15250913798809052,\n",
              " 0.00624827528372407,\n",
              " 0.007714663632214069,\n",
              " 0.03385905548930168,\n",
              " 2.315387064300012e-05,\n",
              " 5.579902335739462e-07,\n",
              " 1.6904937183426227e-06,\n",
              " 0.06423023343086243,\n",
              " 0.06346447765827179,\n",
              " 0.2130013108253479,\n",
              " 0.25210344791412354,\n",
              " 0.0009787882445380092,\n",
              " 0.7259523272514343,\n",
              " 0.6987514495849609,\n",
              " 0.006011337507516146,\n",
              " 0.048292145133018494,\n",
              " 0.037889741361141205,\n",
              " 0.45194366574287415,\n",
              " 0.2865297496318817,\n",
              " 0.013193189166486263,\n",
              " 0.011504748836159706,\n",
              " 8.062816777965054e-05,\n",
              " 0.00020425688126124442,\n",
              " 0.003906708676367998,\n",
              " 0.00031071537523530424,\n",
              " 0.0007166430004872382,\n",
              " 0.00827470887452364,\n",
              " 0.0020388003904372454,\n",
              " 0.013216875493526459,\n",
              " 0.016781650483608246,\n",
              " 0.00011142036237288266,\n",
              " 0.0006057014688849449,\n",
              " 0.00010117334750248119,\n",
              " 0.0002962074941024184,\n",
              " 0.24276047945022583,\n",
              " 0.02562795765697956,\n",
              " 0.001791957183741033,\n",
              " 0.0005971802747808397,\n",
              " 0.06472237408161163,\n",
              " 0.0035856140311807394,\n",
              " 0.14700117707252502,\n",
              " 0.019540393725037575,\n",
              " 0.0034317313693463802,\n",
              " 0.0016588278813287616,\n",
              " 0.005491560325026512,\n",
              " 0.024674441665410995,\n",
              " 6.961139297345653e-05,\n",
              " 4.700762656284496e-05,\n",
              " 1.1078324178015464e-06,\n",
              " 2.6118614186998457e-06]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/train/train_dataset.csv')"
      ],
      "metadata": {
        "id": "Uf5EWYsRD9Xc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "MFyGJ1lpK9q8",
        "outputId": "b5293fcc-452f-436f-afb8-a65c424e2fcc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             image_name  image_label\n",
              "0      images/11731.png            7\n",
              "1       images/2763.png            1\n",
              "2      images/20957.png            5\n",
              "3      images/15221.png            7\n",
              "4      images/16814.png            4\n",
              "...                 ...          ...\n",
              "20204  images/18464.png            4\n",
              "20205   images/1941.png            4\n",
              "20206  images/12660.png            2\n",
              "20207  images/14385.png            5\n",
              "20208   images/3067.png            0\n",
              "\n",
              "[20209 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-004e367d-478b-4815-805d-2912991b62b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>image_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>images/11731.png</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>images/2763.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>images/20957.png</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>images/15221.png</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>images/16814.png</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20204</th>\n",
              "      <td>images/18464.png</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20205</th>\n",
              "      <td>images/1941.png</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20206</th>\n",
              "      <td>images/12660.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20207</th>\n",
              "      <td>images/14385.png</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20208</th>\n",
              "      <td>images/3067.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20209 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-004e367d-478b-4815-805d-2912991b62b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-004e367d-478b-4815-805d-2912991b62b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-004e367d-478b-4815-805d-2912991b62b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e1cad323-0a2b-49f2-90de-e358341f2b8a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1cad323-0a2b-49f2-90de-e358341f2b8a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e1cad323-0a2b-49f2-90de-e358341f2b8a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20209,\n  \"fields\": [\n    {\n      \"column\": \"image_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20209,\n        \"samples\": [\n          \"images/632.png\",\n          \"images/21071.png\",\n          \"images/20910.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1,\n          6,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['image_label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "YQrPKsIWEKyV",
        "outputId": "f8de25f0-144f-4db4-e465-62af42843596"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "image_label\n",
              "7    3317\n",
              "0    2765\n",
              "4    2676\n",
              "2    2610\n",
              "1    2347\n",
              "3    2345\n",
              "6    2233\n",
              "5    1916\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1916</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Step 1: Load the CSV file containing image names and labels\n",
        "csv_file_path = 'train/train_dataset.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Step 2: Create train and validation splits\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['image_label'])\n",
        "\n",
        "# Step 3: Create new directories for train and validation datasets\n",
        "base_dir = 'dataset'\n",
        "os.makedirs(os.path.join(base_dir, 'train'), exist_ok=True)\n",
        "os.makedirs(os.path.join(base_dir, 'val'), exist_ok=True)\n",
        "\n",
        "# Step 4: Create sub-directories for each class in train and val directories\n",
        "for label in df['image_label'].unique():\n",
        "    os.makedirs(os.path.join(base_dir, 'train', str(label)), exist_ok=True)\n",
        "    os.makedirs(os.path.join(base_dir, 'val', str(label)), exist_ok=True)\n",
        "\n",
        "# Step 5: Move the images to their respective directories\n",
        "for _, row in train_df.iterrows():\n",
        "    src = os.path.join('train', row['image_name'])\n",
        "    dst = os.path.join(base_dir, 'train', str(row['image_label']), row['image_name'].split('/')[-1])\n",
        "    shutil.copy(src, dst)\n",
        "\n",
        "for _, row in val_df.iterrows():\n",
        "    src = os.path.join('train', row['image_name'])\n",
        "    dst = os.path.join(base_dir, 'val', str(row['image_label']), row['image_name'].split('/')[-1])\n",
        "    shutil.copy(src, dst)"
      ],
      "metadata": {
        "id": "8K6r7bjFNwEe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch_landmarks(batch_images, landmark_extractor):\n",
        "    \"\"\"\n",
        "    Get a batch of landmarks for a batch of images.\n",
        "\n",
        "    Args:\n",
        "        batch_images (torch.Tensor): A batch of images.\n",
        "        landmark_extractor (nn.Module): The landmark extractor model.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A batch of landmarks.\n",
        "    \"\"\"\n",
        "    # Extract landmarks from each image in the batch\n",
        "    batch_landmarks = []\n",
        "    for image in batch_images:\n",
        "        landmarks = detector.detect(image)\n",
        "        batch_landmarks.append([category.score for category in detection_result.face_blendshapes[0]])\n",
        "\n",
        "    # Stack the landmarks into a batch\n",
        "    batch_landmarks = torch.cat(batch_landmarks, dim=0)\n",
        "\n",
        "    return batch_landmarks"
      ],
      "metadata": {
        "id": "uRFPHqASbPGz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "K1N06Y7rK40U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "from networks.DDAM import DDAMNet\n",
        "import torch.nn.functional as F\n",
        "from sam import SAM\n",
        "eps = sys.float_info.epsilon\n",
        "\n",
        "\n",
        "class ImbalancedDatasetSampler(data.sampler.Sampler):\n",
        "    def __init__(self, dataset, indices: list = None, num_samples: int = None):\n",
        "        self.indices = list(range(len(dataset))) if indices is None else indices\n",
        "        self.num_samples = len(self.indices) if num_samples is None else num_samples\n",
        "\n",
        "        df = pd.DataFrame()\n",
        "        df[\"label\"] = self._get_labels(dataset)\n",
        "        df.index = self.indices\n",
        "        df = df.sort_index()\n",
        "\n",
        "        label_to_count = df[\"label\"].value_counts()\n",
        "\n",
        "        weights = 1.0 / label_to_count[df[\"label\"]]\n",
        "\n",
        "        self.weights = torch.DoubleTensor(weights.to_list())\n",
        "\n",
        "    def _get_labels(self, dataset):\n",
        "        if isinstance(dataset, datasets.ImageFolder):\n",
        "            return [x[1] for x in dataset.imgs]\n",
        "        elif isinstance(dataset, torch.utils.data.Subset):\n",
        "            return [dataset.dataset.imgs[i][1] for i in dataset.indices]\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def __iter__(self):\n",
        "        return (self.indices[i] for i in torch.multinomial(self.weights, self.num_samples, replacement=True))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "class AttentionLoss(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(AttentionLoss, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        num_head = len(x)\n",
        "        loss = 0\n",
        "        cnt = 0\n",
        "        if num_head > 1:\n",
        "            for i in range(num_head-1):\n",
        "                for j in range(i+1, num_head):\n",
        "                    mse = F.mse_loss(x[i], x[j])\n",
        "                    cnt = cnt+1\n",
        "                    loss = loss+mse\n",
        "            loss = cnt/(loss + eps)\n",
        "        else:\n",
        "            loss = 0\n",
        "        return loss\n",
        "\n",
        "\n",
        "def run_training(batch_size, num_workers, lr = 0.01, num_epochs =30):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.enabled = True\n",
        "\n",
        "    model = DDAMNet(num_class=8, num_head=2, pretrained = False)\n",
        "    model.to(device)\n",
        "\n",
        "    data_transforms = transforms.Compose([\n",
        "        transforms.Resize((112, 112)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomApply([\n",
        "                transforms.RandomAffine(20, scale=(0.8, 1), translate=(0.2, 0.2)),\n",
        "            ], p=0.7),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "        transforms.RandomErasing(p=1, scale=(0.05, 0.05)),\n",
        "        ])\n",
        "\n",
        "\n",
        "    train_dataset = datasets.ImageFolder('/content/dataset/train', transform = data_transforms)\n",
        "    #train_subset = torch.utils.data.Subset(train_dataset, range(0, len(train_dataset) // 10))\n",
        "\n",
        "    print('Whole train set size:', train_dataset.__len__())\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size = batch_size,\n",
        "                                               num_workers = num_workers,\n",
        "                                               sampler=ImbalancedDatasetSampler(train_dataset),\n",
        "                                               shuffle = False,\n",
        "                                               pin_memory = True)\n",
        "\n",
        "    data_transforms_val = transforms.Compose([\n",
        "        transforms.Resize((112, 112)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "\n",
        "    val_dataset = datasets.ImageFolder('/content/dataset/val', transform = data_transforms_val)\n",
        "\n",
        "    print('Validation set size:', val_dataset.__len__())\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                               batch_size = batch_size,\n",
        "                                               num_workers = num_workers,\n",
        "                                               shuffle = False,\n",
        "                                               pin_memory = True)\n",
        "\n",
        "\n",
        "    criterion_cls = torch.nn.CrossEntropyLoss().to(device)\n",
        "    criterion_at = AttentionLoss()\n",
        "    params = list(model.parameters())\n",
        "    #optimizer = torch.optim.Adam(params,args.lr,weight_decay = 0)\n",
        "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.6)\n",
        "\n",
        "    optimizer = SAM(model.parameters(), torch.optim.Adam, lr=lr, rho=0.05, adaptive=False, )\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
        "\n",
        "    best_acc = 0\n",
        "    for epoch in tqdm(range(1, num_epochs + 1)):\n",
        "        running_loss = 0.0\n",
        "        correct_sum = 0\n",
        "        iter_cnt = 0\n",
        "        model.train()\n",
        "\n",
        "        for (imgs, targets) in train_loader:\n",
        "            iter_cnt += 1\n",
        "\n",
        "            imgs = imgs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            out,feat,heads = model(imgs)\n",
        "\n",
        "            loss = criterion_cls(out,targets)  + 0.1*criterion_at(heads)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.first_step(zero_grad=True)\n",
        "\n",
        "\n",
        "            imgs = imgs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            out,feat,heads = model(imgs)\n",
        "\n",
        "            loss = criterion_cls(out,targets)  + 0.1*criterion_at(heads)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.second_step(zero_grad=True)\n",
        "            running_loss += loss\n",
        "            _, predicts = torch.max(out, 1)\n",
        "            correct_num = torch.eq(predicts, targets).sum()\n",
        "            correct_sum += correct_num\n",
        "\n",
        "        acc = correct_sum.float() / float(train_dataset.__len__())\n",
        "        running_loss = running_loss/iter_cnt\n",
        "        tqdm.write('[Epoch %d] Training accuracy: %.4f. Loss: %.3f. LR %.6f' % (epoch, acc, running_loss,optimizer.param_groups[0]['lr']))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            running_loss = 0.0\n",
        "            iter_cnt = 0\n",
        "            bingo_cnt = 0\n",
        "            sample_cnt = 0\n",
        "            model.eval()\n",
        "            for imgs, targets in val_loader:\n",
        "\n",
        "                imgs = imgs.to(device)\n",
        "                targets = targets.to(device)\n",
        "                out,feat,heads = model(imgs)\n",
        "\n",
        "                loss = criterion_cls(out,targets)  + 0.1*criterion_at(heads)\n",
        "\n",
        "                running_loss += loss\n",
        "                iter_cnt+=1\n",
        "                _, predicts = torch.max(out, 1)\n",
        "                correct_num  = torch.eq(predicts,targets)\n",
        "                bingo_cnt += correct_num.sum().cpu()\n",
        "                sample_cnt += out.size(0)\n",
        "\n",
        "            running_loss = running_loss/iter_cnt\n",
        "            #scheduler.step()\n",
        "\n",
        "            acc = bingo_cnt.float()/float(sample_cnt)\n",
        "            acc = np.around(acc.numpy(),4)\n",
        "            best_acc = max(acc,best_acc)\n",
        "            tqdm.write(\"[Epoch %d] Validation accuracy:%.4f. Loss:%.3f\" % (epoch, acc, running_loss))\n",
        "            tqdm.write(\"best_acc:\" + str(best_acc))\n",
        "\n",
        "            if  acc > 0.50:\n",
        "                torch.save({'iter': epoch,\n",
        "                            'model_state_dict': model.state_dict(),\n",
        "                             'optimizer_state_dict': optimizer.state_dict(),},\n",
        "                            os.path.join('checkpoints_ver2.0', \"affecnet8_epoch\"+str(epoch)+\"_acc\"+str(acc)+\".pth\"))\n",
        "                tqdm.write('Model saved.')\n",
        "        scheduler.step()\n",
        "if __name__ == \"__main__\":\n",
        "    run_training(128, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "aatLt2PxQ29_",
        "outputId": "afdf3eb8-8952-4db2-c52b-98d7cffd0aa9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whole train set size: 16167\n",
            "Validation set size: 4042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/30 [03:14<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] Training accuracy: 0.1176. Loss: 3.352. LR 0.010000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/30 [03:22<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "  3%|▎         | 1/30 [03:22<1:37:44, 202.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] Validation accuracy:0.1244. Loss:16.948\n",
            "best_acc:0.1244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1/30 [06:32<1:37:44, 202.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 2] Training accuracy: 0.1194. Loss: 2.501. LR 0.009800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 2/30 [06:39<1:33:03, 199.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 2] Validation accuracy:0.1084. Loss:2.866\n",
            "best_acc:0.1244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 2/30 [09:49<1:33:03, 199.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 3] Training accuracy: 0.1240. Loss: 2.339. LR 0.009604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 3/30 [09:57<1:29:26, 198.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 3] Validation accuracy:0.1306. Loss:2.606\n",
            "best_acc:0.1306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 3/30 [13:07<1:29:26, 198.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 4] Training accuracy: 0.1305. Loss: 2.245. LR 0.009412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 4/30 [13:15<1:25:53, 198.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 4] Validation accuracy:0.1338. Loss:2.245\n",
            "best_acc:0.1338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 4/30 [16:24<1:25:53, 198.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 5] Training accuracy: 0.1407. Loss: 2.207. LR 0.009224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 5/30 [16:32<1:22:29, 197.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 5] Validation accuracy:0.1368. Loss:2.194\n",
            "best_acc:0.1368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 5/30 [16:40<1:23:21, 200.06s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-4294ceab2320>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-4294ceab2320>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(batch_size, num_workers, lr, num_epochs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def submission_file_generation(images_path, model_weights_path):\n",
        "\n",
        "  model = DDAMNet(num_class=8, num_head=2, pretrained = False)\n",
        "  model.load_state_dict(torch.load('model-fec.pt', weights_only=True))\n",
        "  model.eval()\n",
        "  result = {'ID': [], 'Target': []}\n",
        "\n",
        "  for img_ in os.listdir(images_path):\n",
        "    image_transformed = transform(Image.open(images_path + img_))\n",
        "    with torch.no_grad():\n",
        "      output = model(image_transformed.unsqueeze(0))\n",
        "      ps = torch.exp(output)\n",
        "      topk, topclass = ps.topk(1, dim = 1)\n",
        "    result['ID'].append(img_)\n",
        "    result['Target'].append(topclass.numpy().squeeze())\n",
        "\n",
        "  return pd.DataFrame.from_records(result).to_csv('result_fce.csv', index=False)"
      ],
      "metadata": {
        "id": "TGxtgC-zdTMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_images = 'test/images/'\n",
        "path_to_model = 'model-fce.pt'\n",
        "\n",
        "submission_file_generation(path_to_images, path_to_model)"
      ],
      "metadata": {
        "id": "Xs_XtCjrvxxU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "7aaaa56f-d1a6-471d-f647-9684d4e9c4de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'model-fec.pt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-b68620b32e69>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath_to_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model-fce.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msubmission_file_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-5eaa974262a8>\u001b[0m in \u001b[0;36msubmission_file_generation\u001b[0;34m(images_path, model_weights_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDAMNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_head\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model-fec.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Target'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model-fec.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('result_fce.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "uliW7amxmwJm",
        "outputId": "0fa2e2d5-9e97-4d6f-9270-e8a0f57aaf21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ID  Target\n",
              "0      3381.png       1\n",
              "1      9085.png       7\n",
              "2      6397.png       3\n",
              "3     23220.png       6\n",
              "4      7112.png       7\n",
              "...         ...     ...\n",
              "5048   7804.png       0\n",
              "5049   9112.png       2\n",
              "5050  13567.png       1\n",
              "5051  16193.png       4\n",
              "5052  15093.png       3\n",
              "\n",
              "[5053 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1f890c6-f2d4-4b29-9e63-3ff38b26d4a9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3381.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9085.png</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6397.png</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23220.png</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7112.png</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5048</th>\n",
              "      <td>7804.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5049</th>\n",
              "      <td>9112.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5050</th>\n",
              "      <td>13567.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5051</th>\n",
              "      <td>16193.png</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5052</th>\n",
              "      <td>15093.png</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5053 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1f890c6-f2d4-4b29-9e63-3ff38b26d4a9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1f890c6-f2d4-4b29-9e63-3ff38b26d4a9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1f890c6-f2d4-4b29-9e63-3ff38b26d4a9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e9de460b-9249-4202-819d-0aa01d31cb30\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e9de460b-9249-4202-819d-0aa01d31cb30')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e9de460b-9249-4202-819d-0aa01d31cb30 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 5053,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5053,\n        \"samples\": [\n          \"21244.png\",\n          \"9823.png\",\n          \"17799.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gqFGODS-oBiE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}